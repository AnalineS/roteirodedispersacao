#!/usr/bin/env python3
"""
Analisador de compatibilidade do PDF para o chatbot
"""

import os
import sys
import pdfplumber
import json
from typing import Dict, List, Tuple
import re

class PDFAnalyzer:
    def __init__(self, pdf_path: str):
        self.pdf_path = pdf_path
        self.analysis = {}
        
    def analyze_pdf(self) -> Dict:
        """Analisa o PDF e retorna informaÃ§Ãµes detalhadas"""
        print(f"ðŸ” Analisando PDF: {self.pdf_path}")
        
        if not os.path.exists(self.pdf_path):
            print(f"âŒ Arquivo nÃ£o encontrado: {self.pdf_path}")
            return {"error": "PDF nÃ£o encontrado"}
        
        try:
            with pdfplumber.open(self.pdf_path) as pdf:
                # InformaÃ§Ãµes bÃ¡sicas
                self.analysis["total_pages"] = len(pdf.pages)
                self.analysis["file_size_mb"] = os.path.getsize(self.pdf_path) / (1024 * 1024)
                
                # Extrair texto
                full_text = ""
                page_texts = []
                
                for page_num, page in enumerate(pdf.pages):
                    page_text = page.extract_text()
                    if page_text:
                        full_text += f"\n--- PÃ¡gina {page_num + 1} ---\n{page_text}\n"
                        page_texts.append({
                            "page": page_num + 1,
                            "text": page_text,
                            "char_count": len(page_text),
                            "word_count": len(page_text.split())
                        })
                
                self.analysis["total_characters"] = len(full_text)
                self.analysis["total_words"] = len(full_text.split())
                self.analysis["page_texts"] = page_texts
                self.analysis["full_text"] = full_text
                
                # AnÃ¡lise de complexidade
                self.analyze_complexity(full_text)
                
                # AnÃ¡lise de compatibilidade
                self.analyze_compatibility()
                
                return self.analysis
                
        except Exception as e:
            print(f"âŒ Erro ao analisar PDF: {e}")
            return {"error": str(e)}
    
    def analyze_complexity(self, text: str):
        """Analisa a complexidade do texto"""
        # EstatÃ­sticas de complexidade
        sentences = re.split(r'[.!?]+', text)
        words = text.split()
        
        # MÃ©dia de palavras por frase
        avg_words_per_sentence = len(words) / len(sentences) if sentences else 0
        
        # Palavras Ãºnicas
        unique_words = set(re.findall(r'\b\w+\b', text.lower()))
        
        # Termos tÃ©cnicos (exemplo para Ã¡rea mÃ©dica)
        technical_terms = [
            'hansenÃ­ase', 'lepra', 'mycobacterium', 'bacilo', 'tratamento',
            'medicamento', 'farmacÃªutico', 'dispensaÃ§Ã£o', 'posologia',
            'dose', 'administraÃ§Ã£o', 'via', 'oral', 'intramuscular',
            'rifampicina', 'dapsona', 'clofazimina', 'poliquimioterapia',
            'protocolo', 'orientaÃ§Ã£o', 'adesÃ£o', 'reaÃ§Ã£o', 'adversa',
            'interaÃ§Ã£o', 'medicamentosa', 'contraindicaÃ§Ã£o', 'precauÃ§Ã£o'
        ]
        
        found_technical_terms = [term for term in technical_terms if term in text.lower()]
        
        self.analysis["complexity"] = {
            "avg_words_per_sentence": round(avg_words_per_sentence, 2),
            "unique_words": len(unique_words),
            "technical_terms_found": len(found_technical_terms),
            "technical_terms": found_technical_terms,
            "text_density": len(text) / self.analysis["total_pages"] if self.analysis["total_pages"] > 0 else 0
        }
    
    def analyze_compatibility(self):
        """Analisa a compatibilidade com o modelo de IA"""
        total_chars = self.analysis["total_characters"]
        total_pages = self.analysis["total_pages"]
        
        # Limites do modelo RoBERTa
        MODEL_MAX_CONTEXT = 512  # tokens (aproximadamente 4000 caracteres)
        RECOMMENDED_CHUNK_SIZE = 2000  # caracteres
        
        # Calcular nÃºmero de chunks necessÃ¡rios
        num_chunks = (total_chars // RECOMMENDED_CHUNK_SIZE) + 1
        
        # AnÃ¡lise de compatibilidade
        compatibility = {
            "model_max_context": MODEL_MAX_CONTEXT,
            "recommended_chunk_size": RECOMMENDED_CHUNK_SIZE,
            "estimated_chunks": num_chunks,
            "total_chars": total_chars,
            "total_pages": total_pages,
            "chars_per_page": total_chars / total_pages if total_pages > 0 else 0
        }
        
        # RecomendaÃ§Ãµes
        recommendations = []
        
        if total_chars > 100000:  # PDF muito grande
            recommendations.append("PDF muito extenso - considere usar chunking avanÃ§ado")
            recommendations.append("Implemente busca semÃ¢ntica para melhor performance")
            compatibility["complexity_level"] = "HIGH"
        elif total_chars > 50000:  # PDF mÃ©dio
            recommendations.append("PDF de tamanho mÃ©dio - chunking recomendado")
            recommendations.append("Considere cache de respostas")
            compatibility["complexity_level"] = "MEDIUM"
        else:  # PDF pequeno
            recommendations.append("PDF de tamanho adequado")
            recommendations.append("Processamento direto possÃ­vel")
            compatibility["complexity_level"] = "LOW"
        
        if total_pages > 50:
            recommendations.append("Muitas pÃ¡ginas - implemente navegaÃ§Ã£o por seÃ§Ãµes")
        
        if self.analysis["complexity"]["technical_terms_found"] > 20:
            recommendations.append("Muitos termos tÃ©cnicos - otimize o dicionÃ¡rio de simplificaÃ§Ã£o")
        
        compatibility["recommendations"] = recommendations
        self.analysis["compatibility"] = compatibility
    
    def generate_optimized_config(self) -> Dict:
        """Gera configuraÃ§Ã£o otimizada baseada na anÃ¡lise"""
        complexity = self.analysis.get("complexity_level", "MEDIUM")
        
        config = {
            "chunk_size": 2000,
            "overlap": 200,
            "max_answer_length": 200,
            "confidence_threshold": 0.3,
            "use_semantic_search": False,
            "use_caching": False,
            "model_name": "deepset/roberta-base-squad2"
        }
        
        if complexity == "HIGH":
            config.update({
                "chunk_size": 1500,
                "overlap": 300,
                "use_semantic_search": True,
                "use_caching": True,
                "max_answer_length": 150
            })
        elif complexity == "MEDIUM":
            config.update({
                "chunk_size": 2000,
                "overlap": 200,
                "use_caching": True
            })
        
        return config
    
    def print_analysis(self):
        """Imprime a anÃ¡lise de forma organizada"""
        print("\n" + "="*60)
        print("ðŸ“Š ANÃLISE DE COMPATIBILIDADE DO PDF")
        print("="*60)
        
        if "error" in self.analysis:
            print(f"âŒ Erro: {self.analysis['error']}")
            return
        
        print(f"ðŸ“„ InformaÃ§Ãµes BÃ¡sicas:")
        print(f"   - PÃ¡ginas: {self.analysis['total_pages']}")
        print(f"   - Tamanho: {self.analysis['file_size_mb']:.2f} MB")
        print(f"   - Caracteres: {self.analysis['total_characters']:,}")
        print(f"   - Palavras: {self.analysis['total_words']:,}")
        
        print(f"\nðŸ§  Complexidade:")
        comp = self.analysis["complexity"]
        print(f"   - Palavras por frase: {comp['avg_words_per_sentence']}")
        print(f"   - Palavras Ãºnicas: {comp['unique_words']:,}")
        print(f"   - Termos tÃ©cnicos: {comp['technical_terms_found']}")
        
        print(f"\nâš™ï¸ Compatibilidade:")
        compat = self.analysis["compatibility"]
        print(f"   - NÃ­vel: {compat['complexity_level']}")
        print(f"   - Chunks estimados: {compat['estimated_chunks']}")
        print(f"   - Caracteres por pÃ¡gina: {compat['chars_per_page']:.0f}")
        
        print(f"\nðŸ’¡ RecomendaÃ§Ãµes:")
        for rec in compat["recommendations"]:
            print(f"   - {rec}")
        
        print(f"\nðŸ”§ ConfiguraÃ§Ã£o Otimizada:")
        config = self.generate_optimized_config()
        for key, value in config.items():
            print(f"   - {key}: {value}")
        
        print("="*60)

def main():
    """FunÃ§Ã£o principal"""
    pdf_path = "Roteiro-de-Dsispensacao-Hanseniase-F.docx.pdf"
    
    if len(sys.argv) > 1:
        pdf_path = sys.argv[1]
    
    analyzer = PDFAnalyzer(pdf_path)
    analysis = analyzer.analyze_pdf()
    
    if "error" not in analysis:
        analyzer.print_analysis()
        
        # Salvar anÃ¡lise em JSON
        with open("pdf_analysis.json", "w", encoding="utf-8") as f:
            json.dump(analysis, f, ensure_ascii=False, indent=2)
        print(f"\nðŸ’¾ AnÃ¡lise salva em: pdf_analysis.json")
        
        # Gerar configuraÃ§Ã£o otimizada
        config = analyzer.generate_optimized_config()
        with open("optimized_config.json", "w", encoding="utf-8") as f:
            json.dump(config, f, ensure_ascii=False, indent=2)
        print(f"ðŸ’¾ ConfiguraÃ§Ã£o salva em: optimized_config.json")

if __name__ == "__main__":
    main() 