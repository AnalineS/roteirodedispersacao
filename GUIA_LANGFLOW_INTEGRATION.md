# ğŸ¨ GUIA COMPLETO - INTEGRAÃ‡ÃƒO COM LANGFLOW

## ğŸ“‹ VisÃ£o Geral

Este guia mostra como integrar o **Langflow** com seu chatbot de hansenÃ­ase, criando fluxos visuais de IA mais avanÃ§ados e flexÃ­veis.

## ğŸ¯ O que Ã© o Langflow?

**Langflow** Ã© uma ferramenta visual para criar fluxos de IA (LLM workflows) sem cÃ³digo. Permite:
- âœ… Criar fluxos visuais de IA
- âœ… Conectar diferentes modelos e componentes
- âœ… Testar e iterar rapidamente
- âœ… Deploy de fluxos como APIs
- âœ… Interface web intuitiva

## ğŸš€ Vantagens da IntegraÃ§Ã£o

### Para seu Chatbot de HansenÃ­ase:
- **Fluxos Visuais**: Crie pipelines de IA arrastando e soltando
- **MÃºltiplos Modelos**: Combine diferentes modelos de IA
- **Processamento AvanÃ§ado**: Chunking, embeddings, busca semÃ¢ntica
- **Fallback Inteligente**: Sistema padrÃ£o como backup
- **Monitoramento**: Logs e mÃ©tricas detalhadas

## ğŸ“¦ Arquivos Criados

### ğŸ”§ Arquivos de IntegraÃ§Ã£o
- **`langflow_integration.py`** - Classe principal de integraÃ§Ã£o
- **`app_with_langflow.py`** - App Flask com integraÃ§Ã£o automÃ¡tica
- **`setup_langflow.bat`** - Script de instalaÃ§Ã£o automÃ¡tica

### ğŸ“‹ Guias e DocumentaÃ§Ã£o
- **`GUIA_LANGFLOW_INTEGRATION.md`** - Este guia completo

## ğŸ› ï¸ InstalaÃ§Ã£o e ConfiguraÃ§Ã£o

### Passo 1: InstalaÃ§Ã£o AutomÃ¡tica (Recomendado)
```bash
# Execute o script de instalaÃ§Ã£o
setup_langflow.bat
```

### Passo 2: InstalaÃ§Ã£o Manual
```bash
# Instalar Langflow
pip install langflow

# Instalar dependÃªncias adicionais
pip install requests typing-extensions

# Testar instalaÃ§Ã£o
python langflow_integration.py
```

### Passo 3: Iniciar o Langflow
```bash
# Iniciar servidor Langflow
langflow run

# Acessar interface web
# http://localhost:7860
```

## ğŸ¨ Criando Fluxos no Langflow

### Fluxo BÃ¡sico para HansenÃ­ase

1. **Acesse a Interface**
   - VÃ¡ para: http://localhost:7860
   - Clique em "Create New Flow"

2. **Adicione Componentes**
   ```
   Input â†’ Document Loader â†’ Text Splitter â†’ 
   Embedding Model â†’ Vector Store â†’ 
   Retriever â†’ LLM â†’ Prompt Template â†’ Output
   ```

3. **Configure Cada Componente**

#### Input Node
```json
{
  "input_type": "str",
  "required": true,
  "placeholder": "Digite sua pergunta sobre hansenÃ­ase"
}
```

#### Document Loader
```json
{
  "file_path": "PDFs/Roteiro de DsispensaÃ§Ã£o - HansenÃ­ase.md",
  "loader_type": "markdown"
}
```

#### Text Splitter
```json
{
  "chunk_size": 1500,
  "chunk_overlap": 300,
  "separator": "\n\n"
}
```

#### Embedding Model
```json
{
  "model_name": "all-MiniLM-L6-v2",
  "device": "cpu"
}
```

#### Vector Store
```json
{
  "store_type": "memory",
  "similarity_metric": "cosine"
}
```

#### Retriever
```json
{
  "top_k": 3,
  "similarity_threshold": 0.3
}
```

#### LLM Node
```json
{
  "model_name": "deepset/roberta-base-squad2",
  "task": "question-answering",
  "max_length": 512
}
```

#### Prompt Template
```json
{
  "template": """
  VocÃª Ã© um especialista em hansenÃ­ase. Responda baseado no contexto fornecido.
  
  Personalidade: {personality}
  - Dr. Gasnelio: Tom sÃ©rio e tÃ©cnico, linguagem formal
  - GÃ¡: Tom descontraÃ­do e acessÃ­vel, linguagem simples
  
  Contexto: {context}
  Pergunta: {question}
  
  Resposta:
  """,
  "input_variables": ["personality", "context", "question"]
}
```

## ğŸ”— IntegraÃ§Ã£o com seu Sistema

### OpÃ§Ã£o 1: Sistema HÃ­brido (Recomendado)
```python
# Usar app_with_langflow.py
python app_with_langflow.py
```

**Vantagens:**
- âœ… Detecta Langflow automaticamente
- âœ… Fallback para sistema padrÃ£o
- âœ… Cache inteligente
- âœ… Monitoramento completo

### OpÃ§Ã£o 2: IntegraÃ§Ã£o Manual
```python
from langflow_integration import HanseniaseLangflowBridge

# Criar bridge
bridge = HanseniaseLangflowBridge()

# Configurar ambiente
setup_result = bridge.setup_langflow_environment()

# Processar pergunta
result = bridge.answer_question(
    question="Qual o tratamento para hansenÃ­ase?",
    personality="dr_gasnelio"
)
```

## ğŸ“Š Monitoramento e Logs

### Endpoints de Monitoramento
```bash
# Status do sistema
GET /api/system-status

# Health check
GET /api/health

# InformaÃ§Ãµes da API
GET /api/info
```

### Logs Importantes
```python
# Verificar se Langflow estÃ¡ ativo
if chatbot.use_langflow:
    print("âœ… Langflow ativo")
else:
    print("â„¹ï¸ Usando sistema padrÃ£o")

# Verificar cache
print(f"Cache size: {len(chatbot.cache)}")

# Verificar chunks
print(f"Chunks loaded: {len(chatbot.chunks)}")
```

## ğŸ¯ Fluxos AvanÃ§ados

### Fluxo 1: AnÃ¡lise de Documentos
```
Input â†’ Document Loader â†’ Text Splitter â†’ 
Embedding â†’ Vector Store â†’ 
Retriever â†’ LLM â†’ 
Sentiment Analysis â†’ Output
```

### Fluxo 2: Resposta Personalizada
```
Input â†’ Personality Detector â†’ 
Document Loader â†’ Text Splitter â†’ 
Embedding â†’ Vector Store â†’ 
Retriever â†’ LLM â†’ 
Personality Filter â†’ Output
```

### Fluxo 3: ValidaÃ§Ã£o MÃ©dica
```
Input â†’ Medical Term Extractor â†’ 
Document Loader â†’ Text Splitter â†’ 
Embedding â†’ Vector Store â†’ 
Retriever â†’ LLM â†’ 
Medical Validator â†’ Output
```

## ğŸ”§ ConfiguraÃ§Ã£o AvanÃ§ada

### VariÃ¡veis de Ambiente
```bash
# .env
LANGFLOW_API_KEY=your_api_key_here
LANGFLOW_URL=http://localhost:7860
LANGFLOW_FLOW_ID=hanseniase_default
```

### ConfiguraÃ§Ã£o de Cache
```python
# Cache persistente
import pickle

def save_cache(cache, filename="langflow_cache.pkl"):
    with open(filename, 'wb') as f:
        pickle.dump(cache, f)

def load_cache(filename="langflow_cache.pkl"):
    try:
        with open(filename, 'rb') as f:
            return pickle.load(f)
    except:
        return {}
```

### ConfiguraÃ§Ã£o de Modelos
```python
# Modelos alternativos
MODELS_CONFIG = {
    "qa_model": "deepset/roberta-base-squad2",
    "embedding_model": "all-MiniLM-L6-v2",
    "text_generation": "gpt2",
    "sentiment": "cardiffnlp/twitter-roberta-base-sentiment"
}
```

## ğŸš¨ SoluÃ§Ã£o de Problemas

### Erro: "Langflow nÃ£o disponÃ­vel"
**Causas:**
- Langflow nÃ£o instalado
- Servidor nÃ£o iniciado
- Porta bloqueada

**SoluÃ§Ãµes:**
```bash
# 1. Instalar Langflow
pip install langflow

# 2. Iniciar servidor
langflow run

# 3. Verificar porta
netstat -an | findstr 7860
```

### Erro: "Flow nÃ£o encontrado"
**Causas:**
- Fluxo nÃ£o criado
- ID incorreto
- PermissÃµes

**SoluÃ§Ãµes:**
```python
# 1. Criar fluxo
flow_result = langflow.create_hanseniase_flow()

# 2. Verificar fluxos disponÃ­veis
flows = langflow.get_available_flows()

# 3. Usar ID correto
result = langflow.process_question(question, flow_id=flow_result["id"])
```

### Erro: "Timeout na resposta"
**Causas:**
- Modelo muito lento
- Chunks muito grandes
- Sem cache

**SoluÃ§Ãµes:**
```python
# 1. Reduzir chunk size
chunk_size = 1000  # em vez de 1500

# 2. Usar cache
cache_enabled = True

# 3. Timeout maior
timeout = 120  # segundos
```

## ğŸ“ˆ MÃ©tricas e Performance

### MÃ©tricas Importantes
- **Tempo de resposta**: < 5 segundos
- **Taxa de cache hit**: > 60%
- **ConfianÃ§a mÃ©dia**: > 40%
- **Erros**: < 5%

### OtimizaÃ§Ãµes
```python
# 1. Cache inteligente
cache_ttl = 3600  # 1 hora

# 2. Chunking otimizado
chunk_size = 1500
chunk_overlap = 300

# 3. Threshold ajustÃ¡vel
similarity_threshold = 0.3
```

## ğŸ‰ Exemplos de Uso

### Exemplo 1: Pergunta Simples
```python
# Pergunta sobre tratamento
result = chatbot.answer_question(
    "Qual Ã© o tratamento para hansenÃ­ase?",
    "dr_gasnelio"
)

print(result["answer"])
# Dr. Gasnelio responde:
# Baseado na minha tese, o tratamento para hansenÃ­ase...
```

### Exemplo 2: Pergunta com GÃ¡
```python
# Pergunta informal
result = chatbot.answer_question(
    "Como eu sei se tenho hansenÃ­ase?",
    "ga"
)

print(result["answer"])
# GÃ¡ explica: Olha, se vocÃª tem manchas na pele que nÃ£o doem...
```

### Exemplo 3: Monitoramento
```python
# Verificar status
status = chatbot.get_system_info()

print(f"Langflow ativo: {status['langflow_active']}")
print(f"Cache size: {status['cache_size']}")
print(f"Chunks: {status['chunks_loaded']}")
```

## ğŸ”„ Deploy com Langflow

### Deploy Local
```bash
# 1. Iniciar Langflow
langflow run

# 2. Iniciar chatbot
python app_with_langflow.py

# 3. Acessar
# http://localhost:5000
```

### Deploy em ProduÃ§Ã£o
```bash
# 1. Configurar Langflow
export LANGFLOW_API_KEY=your_key
export LANGFLOW_URL=https://your-langflow-server.com

# 2. Deploy chatbot
gunicorn app_with_langflow:app

# 3. Configurar proxy reverso
# Nginx/Apache para rotear /api/* para Langflow
```

## ğŸ“š Recursos Adicionais

### DocumentaÃ§Ã£o Oficial
- **Langflow Docs**: https://docs.langflow.org/
- **API Reference**: https://docs.langflow.org/api
- **Examples**: https://github.com/logspace-ai/langflow

### Comunidade
- **Discord**: https://discord.gg/langflow
- **GitHub**: https://github.com/logspace-ai/langflow
- **Twitter**: @LangflowAI

## âœ… Checklist de IntegraÃ§Ã£o

### PrÃ©-requisitos
- [ ] Python 3.9+ instalado
- [ ] PDF da tese presente
- [ ] DependÃªncias instaladas

### InstalaÃ§Ã£o
- [ ] Langflow instalado
- [ ] Script de setup executado
- [ ] Servidor Langflow rodando

### ConfiguraÃ§Ã£o
- [ ] Fluxo criado no Langflow
- [ ] IntegraÃ§Ã£o testada
- [ ] Fallback funcionando

### Testes
- [ ] Perguntas simples
- [ ] Perguntas complexas
- [ ] Ambas personalidades
- [ ] Monitoramento

## ğŸ¯ PrÃ³ximos Passos

1. **Teste a integraÃ§Ã£o** com perguntas simples
2. **Crie fluxos personalizados** no Langflow
3. **Otimize performance** com cache e chunking
4. **Configure monitoramento** e logs
5. **Deploy em produÃ§Ã£o** com Langflow

---

**ğŸ‰ Sucesso!** Seu chatbot agora tem integraÃ§Ã£o completa com Langflow!

### URLs Importantes
- **Chatbot**: http://localhost:5000
- **Langflow**: http://localhost:7860
- **API Status**: http://localhost:5000/api/system-status 